{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import hddm\n",
    "from sys import platform\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from jupyterthemes import jtplot\n",
    "import matplotlib.pyplot as plt\n",
    "from kabuki.analyze import gelman_rubin\n",
    "\n",
    "\n",
    "\n",
    "jtplot.style(theme='onedork')\n",
    "jtplot.style(context='poster', fscale=2, spines=False, gridlines='--')\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == 'linux2':\n",
    "    home = '/home/krista/'\n",
    "elif platform == 'darwin': \n",
    "    home = '/Users/Krista/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs_data = hddm.load_csv(home + 'Dropbox/loki_0.5/analysis/aggregated_data/reward_ls_combined.csv')\n",
    "all_obs_data = all_obs_data.rename(index=str, columns={\"p_accuracy\": \"response\",\n",
    "                                                       \"subj_id\": \"subj_idx\"})\n",
    "all_obs_data = all_obs_data[['response', 'rt', 'reward_code', 'subj_idx', 'ideal_B', 'cpp']] \n",
    "all_obs_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs_data['cpp_shifted'] = all_obs_data.cpp.shift(1)\n",
    "all_obs_data['ideal_B_shifted'] = all_obs_data.ideal_B.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs_data.dropna(inplace=True) #need to drop nas for HDDMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_burn = 3000, 500\n",
    "n_effective_samples = n_samples - n_burn\n",
    "subjects = all_obs_data.subj_idx.unique()\n",
    "\n",
    "model_specifications = [('a~cpp_shifted', 'v~ideal_B_shifted'),\n",
    "                        ('v~cpp_shifted', 'a~ideal_B_shifted'),\n",
    "          ('a~1', 't~1', 'v~1')]\n",
    "model_names = ['a_cpp_v_B', 'v_cpp_a_B', 'intercept']\n",
    "\n",
    "model_inputs = dict(zip(model_names, model_specifications))\n",
    "model_objects = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_regression_model(model_specification, model_name, subject, data, model_objects,\n",
    "                              n_samples=n_samples, n_burn=n_burn, accuracy_coding=True, convergence_iteration=None):\n",
    "    \n",
    "    if accuracy_coding: \n",
    "        reg_model = hddm.HDDMRegressor(data = data, models = model_specification, bias=False, group_only_regressors=True, p_outlier=0.05) #accuracy coded\n",
    "        reg_model.find_starting_values()\n",
    "        reg_model.sample(n_samples, burn = n_burn, dbname = model_name, db='pickle')\n",
    "    else: \n",
    "        reg_model = hddm.HDDMRegressor(data = data, models = model_specification, bias=True, group_only_regressors=True, p_outlier=0.05) #stim coded\n",
    "        reg_model.find_starting_values()\n",
    "        reg_model.sample(n_samples, burn=n_burn, dbname=model_name+'.db', db='pickle')\n",
    "    \n",
    "    if convergence_iteration is None: \n",
    "        model_objects[model_name + '_' + str(subject)] = reg_model\n",
    "    else:\n",
    "        model_objects[model_name + '_' + str(subject) + '_iter' + str(convergence_iteration)] = reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    sub_data = all_obs_data.loc[all_obs_data.subj_idx == subject,]\n",
    "    for model_name, model_specification in model_inputs.items(): \n",
    "        estimate_regression_model(model_specification, model_name, subject, sub_data, model_objects)\n",
    "        print('model sampling complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run each model for each subject 5 times to estimate between-chain variance \n",
    "n_convergence_iterations = 5\n",
    "model_convergence_objects = dict() \n",
    "\n",
    "for subject in subjects:\n",
    "    sub_data = all_obs_data.loc[all_obs_data.subj_idx == subject,]\n",
    "    for convergence_iteration in range(n_convergence_iterations):\n",
    "        for model_name, model_specification in model_inputs.items(): \n",
    "            estimate_regression_model(model_specification=model_specification, model_name = model_name, subject=subject, \n",
    "                                      data=sub_data, model_objects=model_convergence_objects, convergence_iteration=convergence_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(model_names)\n",
    "print(n_models)\n",
    "len(model_convergence_objects) == (len(subjects) * n_convergence_iterations * n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_criterion = 1.1 #max. acceptable ratio of between to within chain variance (see Gelman)\n",
    "subjects = all_obs_data.subj_idx.unique().astype('str')\n",
    "search_strings = [model_name + '_' +  subject for model in model_names for subject in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconverged = list()\n",
    "\n",
    "for string in search_strings:\n",
    "        data = dict((key, value) for key, value in model_convergence_objects.iteritems() if key.startswith(string))\n",
    "        R_dict = gelman_rubin(data.values()) #create dict of R hat statistics for each parameter  \n",
    "        print(R_dict)\n",
    "        unconverged.append(any(param > var_criterion for param in R_dict.itervalues())) #check whether stat. exceeds criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_unconverged_params = sum(unconverged) #find number of unconverged parameters \n",
    "print('all parameters have converged:' , n_unconverged_params == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals().update(model_objects) # convert keys and values to variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subj_df_list) == (len(subjects) * n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subj_df_all) == (len(subjects)*n_models*n_effective_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cpp_v_B = [a_cpp_v_B_786, a_cpp_v_B_787, a_cpp_v_B_788, a_cpp_v_B_789]\n",
    "v_cpp_a_B = [v_cpp_a_B_786, v_cpp_a_B_787, v_cpp_a_B_788, v_cpp_a_B_789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = [intercept_786, intercept_787, intercept_788, intercept_789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [a_cpp_v_B, v_cpp_a_B, intercept]\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict(zip(model_names, all_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df_list = []\n",
    "\n",
    "for model in model_dict:\n",
    "    for subject in range(len(subjects)):\n",
    "        subj_df = model_dict[model][subject].get_traces()\n",
    "        subj_df['subj_idx'] = model_dict[model][subject].data.subj_idx.unique().tolist() * n_effective_samples\n",
    "        subj_df['model'] = model\n",
    "        subj_df['dic'] = model_dict[model][subject].dic\n",
    "        subj_df_list.append(subj_df)\n",
    "    \n",
    "subj_df_all = pd.concat(subj_df_list, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df_all.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df_all.groupby(['subj_idx', 'model'])['dic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_df = (subj_df_all.groupby(['subj_idx', 'model'])['dic'].unique() - subj_df_all.loc[subj_df_all.model == 'intercept'].groupby(['subj_idx'])['dic'].unique()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_df['raw_dic'] = subj_df_all.groupby(['subj_idx', 'model'])['dic'].unique().reset_index()['dic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_df = dics_df.rename(index=str, columns={\"dic\": \"null_adj_dic\"})\n",
    "dics_df['null_adj_dic'] = dics_df['null_adj_dic'].str[0]\n",
    "dics_df['raw_dic'] = dics_df['raw_dic'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df_all.to_csv(home + 'Dropbox/loki_0.5/analysis/aggregated_data/subjectwise_ddm_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_df.to_csv(home + 'Dropbox/loki_0.5/analysis/aggregated_data/subjectwise_dics_reg.csv' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
